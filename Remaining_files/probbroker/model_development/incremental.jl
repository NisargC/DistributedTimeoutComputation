include("shared.jl")
using Gen
using PyPlot
using StatsBase
"""
Data type used in return value of the production kernel (V).
"""
struct NodeTypeAndXs
    node_type::Int
    xs::Vector{Float64}
end

"""
Data type for the return value of the aggregation kernel (W)
"""
struct CovFnAndMatrix
    node::Node
    cov_matrix::Matrix{Float64}
end

@gen (static) function production_kernel(xs::Vector{Float64})


    node_type = @trace(Gen.categorical(node_dist), :type)

    # to be passed to the corresponding aggregation kernel application
    v = NodeTypeAndXs(node_type, xs)

    # elements to be passed to each child production kernel application
    num_children = node_type_to_num_children[node_type]
    us = fill(xs, num_children)

    result = Production(v, us)
    return result
end

@gen function aggregation_kernel(node_type_and_xs::NodeTypeAndXs,
                                          child_outputs::Vector{CovFnAndMatrix})

    node_type::Int = node_type_and_xs.node_type
    xs::Vector{Float64} = node_type_and_xs.xs
    local node::Node
    local cov_matrix::Matrix{Float64}

    # constant kernel
    if node_type == CONSTANT
        @assert length(child_outputs) == 0
        param = @trace(uniform_continuous(0, 1), :param)
        node = Constant(param)
        cov_matrix = eval_cov_mat(node, xs)

    # linear kernel
    elseif node_type == LINEAR
        @assert length(child_outputs) == 0
        param = @trace(uniform_continuous(0, 1), :param)
        node = Linear(param)
        cov_matrix = eval_cov_mat(node, xs)

    # squared exponential kernel
    elseif node_type == SQUARED_EXP
        @assert length(child_outputs) == 0
        length_scale = 0.01 + @trace(uniform_continuous(0, 1), :length_scale)
        node = SquaredExponential(length_scale)
        cov_matrix = eval_cov_mat(node, xs)

    # periodic kernel
    elseif node_type == PERIODIC
        @assert length(child_outputs) == 0
        scale = 0.01 + @trace(uniform_continuous(0, 1), :scale)
        period = 0.01 + @trace(uniform_continuous(0, 1), :period)
        node = Periodic(scale, period)
        cov_matrix = eval_cov_mat(node, xs)

    # plus combinator
    elseif node_type == PLUS
        @assert length(child_outputs) == 2
        node = Plus(child_outputs[1].node, child_outputs[2].node)
        cov_matrix = child_outputs[1].cov_matrix .+ child_outputs[2].cov_matrix

    # times combinator
    elseif node_type == TIMES
        @assert length(child_outputs) == 2
        node = Times(child_outputs[1].node, child_outputs[2].node)
        cov_matrix = child_outputs[1].cov_matrix .* child_outputs[2].cov_matrix

    else
        error("unknown node type $node_type")
    end

    # to be passed to the parent aggregation kernel application
    w = CovFnAndMatrix(node, cov_matrix)

    return w
end

const covariance_prior_incremental = Recurse(
        production_kernel, aggregation_kernel,
        max_branch, # maximum number of children generated by production
        Vector{Float64}, # U (passed from production to its children)
        NodeTypeAndXs, # V (passed from production to aggregation)
        CovFnAndMatrix) # W (passed from aggregation to its parents, also Recurse's return type)

@gen (static) function model(xs::Vector{Float64})

    # sample covariance matrix
    cov_fn_and_matrix = @trace(covariance_prior_incremental(xs, 1), :tree)

    # sample diagonal noise
    noise = @trace(gamma(1, 1), :noise)

    # compute covariance matrix
    n = length(xs)
    cov_matrix = cov_fn_and_matrix.cov_matrix + Matrix((noise + 0.01) * LinearAlgebra.I, n, n)

    # sample from multivariate normal
    @trace(mvnormal(zeros(n), cov_matrix), :ys)

    node = cov_fn_and_matrix.node
    return node
end

Gen.load_generated_functions()

@gen function subtree_proposal_recursive(cur::Int)

    # base address for production kernel application 'cur'
    prod_addr = (cur, Val(:production))

    # base address for aggregation kernel application 'cur'
    agg_addr = (cur, Val(:aggregation))

    # sample node type
    node_type = @trace(Gen.categorical(node_dist), (cur, Val(:production)) => :type)

    # constant kernel
    if node_type == CONSTANT
        @trace(uniform_continuous(0, 1), agg_addr => :param)

    # linear kernel
    elseif node_type == LINEAR
        @trace(uniform_continuous(0, 1), agg_addr => :param)

    # squared exponential kernel
    elseif node_type == SQUARED_EXP
        @trace(uniform_continuous(0, 1), agg_addr => :length_scale)

    # periodic kernel
    elseif node_type == PERIODIC
        @trace(uniform_continuous(0, 1), agg_addr => :scale)
        @trace(uniform_continuous(0, 1), agg_addr => :period)

    # plus combinator
    elseif node_type == PLUS
        child1 = get_child(cur, 1, max_branch)
        child2 = get_child(cur, 2, max_branch)
        @trace(subtree_proposal_recursive(child1))
        @trace(subtree_proposal_recursive(child2))

    # times combinator
    elseif node_type == TIMES
        child1 = get_child(cur, 1, max_branch)
        child2 = get_child(cur, 2, max_branch)
        @trace(subtree_proposal_recursive(child1))
        @trace(subtree_proposal_recursive(child2))

    # unknown node type
    else
        error("Unknown node type: $node_type")
    end

    node_type
end

@gen function subtree_proposal(prev_trace)
    prev_subtree_node::Node = get_retval(prev_trace)
    (subtree_idx::Int, depth::Int) = @trace(pick_random_node(prev_subtree_node, 1, 0), :choose_subtree_root)
    new_subtree_node_type::Int = @trace(subtree_proposal_recursive(subtree_idx), :subtree)
    (subtree_idx, depth, new_subtree_node_type)
end

function subtree_involution(trace, fwd_choices::ChoiceMap, fwd_ret::Tuple, proposal_args::Tuple)
    (subtree_idx, subtree_depth, new_subtree_type) = fwd_ret
    model_args = get_args(trace)

    # populate constraints
    constraints = choicemap()
    set_submap!(constraints, :tree, get_submap(fwd_choices, :subtree))

    # obtain new trace and discard, which contains the previous subtree
    (new_trace, weight, _, discard) = update(trace, model_args, (NoChange(),), constraints)

    # populate backward assignment
    bwd_choices = choicemap()
    set_submap!(bwd_choices, :choose_subtree_root => :recurse_left,
        get_submap(fwd_choices, :choose_subtree_root => :recurse_left))
    for depth=0:subtree_depth-1
        bwd_choices[:choose_subtree_root => :done => depth] = false
    end
    if new_subtree_type in BINARY_OPS
        bwd_choices[:choose_subtree_root => :done => subtree_depth] = true
    end
    set_submap!(bwd_choices, :subtree, get_submap(discard, :tree))

    (new_trace, bwd_choices, weight)
end


@gen function noise_proposal(prev_trace)
    @trace(gamma(1, 1), :noise)
end

function inference(xs::Vector{Float64}, ys::Vector{Float64}, num_iters::Int, callback)

    # observed data
    constraints = choicemap()
    constraints[:ys] = ys

    # generate initial trace consistent with observed data
    (trace, _) = generate(model, (xs,), constraints)

    # do MCMC
    local covariance_fn::Node
    local noise::Float64
    for iter=1:num_iters

        covariance_fn = get_retval(trace)
        noise = trace[:noise]
        callback(covariance_fn, noise)

        # randomly pick a node to expand
        #root = pick_random_node(covariance_fn, 1, max_branch)

        # do MH move on the subtree
        (trace, _) = metropolis_hastings(trace, subtree_proposal, (), subtree_involution)

        # do MH move on the top-level white noise
        (trace, _) = metropolis_hastings(trace, noise_proposal, ())
    end
    #println(trace)
    return (covariance_fn, noise)
end
 function plot_predictions(xs, ys, new_xs, pred_ys, endpoint, path)
     clf()
     figure()


     scatter(xs, ys, color="black", label="Actuals")
     i=0
     for pred_ys_single in pred_ys
         if i == 0
             scatter(new_xs, pred_ys_single, color="green", s=1, alpha=0.3, label="Individual Prediction")
         else
             scatter(new_xs, pred_ys_single, color="green", s=1, alpha=0.3)
         end
         i = i+1

     end
     scatter(new_xs, mean(pred_ys), color="green", alpha=.7, label="Ensemble Prediction")
    title(endpoint)
    ylabel("Response Time (millis)")
    xlabel("Time (% of of run)")
    legend()

    savefig( "$(endpoint).png", bbox_inches = "tight", pad_inches = 0.1 )
    gcf()

 end;

function run_predictions(num_samples::Int, endpoint::String, seconds_lookback::Int, numPredicted::Int, path::String, iterations::Int)

    # load and rescale the dataset
    #numPredicted = convert(Int, seconds_lookforward/10) # 20 second intervals
    alldata = @time get_model_data(endpoint, path) #2 hours was too much
    #alldata = first(alldata, 1000)

    if nrow(alldata) == 0
        return 1234
    end

    for subdf in groupby(alldata, :service_name)
        #show(subdf)
        xs = subdf[:xs]
        ys = subdf[:ys]
        #on the original scale
        ys_plot = subdf[:mean_millis]
        split = length(xs)-numPredicted
        xs_train = xs[1:split]
        ys_train = ys[1:split]


        xs_test = xs[split+1:end]
        ys_test = ys[split+1:end]
        ys_test_orig_scale = ys_plot[split+1:end]
        println("NUM Xs Train " , length(xs_train))
        all_pred_ys = []
        max_pred_ys = []
        for i in 1:num_samples

            # set seed
            Random.seed!(i)

            # print MSE and predictive log likelihood on test data
            callback = (covariance_fn, noise) -> begin
                pred_ll = predictive_ll(covariance_fn, noise, xs_train, ys_train, xs_test, ys_test)
                mse = compute_mse(covariance_fn, noise, xs_train, ys_train, xs_test, ys_test)
                #println("mse: $mse, predictive log likelihood: $pred_ll")
            end


            # do inference, time it
            (covariance_fn, noise) = inference(xs_train, ys_train, iterations, callback)

            # sample predictions
            pred_ys = predict_ys(covariance_fn, noise, xs_train, ys_train, xs_test)

            #println("Ys Train")
            #println(ys_train)
            #println("Ys Pred")
            #println(pred_ys)
            #revert the inbound process to recover on the correct scale
            unys = subdf.mean_millis .- mean(subdf.mean_millis) #
            pred_ys = pred_ys .* (maximum(unys) - minimum(unys)) / 4
            pred_ys .+= mean(subdf.mean_millis)
            #ys_train = ys_train .* (maximum(unys) - minimum(unys)) / 4
            #ys_train .+= mean(subdf.mean_millis)

            # if i == 1
            #     max_pred_ys = pred_ys
            # else
            #     foreach()
            #     max_pred_ys = max(max_pred_ys, pred_ys)
            # end
            push!(all_pred_ys,pred_ys)




        end

        display(plot_predictions(xs, ys_plot, xs_test, all_pred_ys, endpoint,path))
        diff = ys_test_orig_scale - mean(all_pred_ys)

        #println(all_pred_ys)
        #println(max_pred_ys)
        # count > 0 -> underpredict - very bad
        println("Under predict count: ", count( x-> x > 0, diff))
        println("Over predict count: ", count( x-> x < 0, diff))
        # count < 0 -> overpredict - good
        # %err of overpredict
        # %err of underpredict

    end
end

function runpreds_highlow()
    println("Auth")
    @time run_predictions(20, "auth.default", 1, 60, "high_low_cycle/raw_max_20s.csv", 1000)
    println("Customer")
    @time run_predictions(20, "customer.default", 1, 60, "high_low_cycle/raw_max_20s.csv", 1000)
    println("Flight")
    @time run_predictions(20, "flight.default", 1, 60, "high_low_cycle/raw_max_20s.csv", 1000)
    println("Booking")
    @time run_predictions(20, "booking.default", 1, 60, "high_low_cycle/raw_max_20s.csv", 1000)
end
function runpreds_longramp()
    println("Auth")
    @time run_predictions(100, "auth.default", 1, 60, "long_ramp/raw_max_20s.csv", 100)
    println("Customer")
    @time run_predictions(100, "customer.default", 1, 60, "long_ramp/raw_max_20s.csv", 100)
    println("Flight")
    @time run_predictions(100, "flight.default", 1, 60, "long_ramp/raw_max_20s.csv", 100)
    println("Booking")
    @time run_predictions(100, "booking.default", 1, 60, "long_ramp/raw_max_20s.csv", 100)
end
function runpreds_random()
    println("Auth")
    @time run_predictions(20, "auth.default", 1, 100, "random/raw_max_20s.csv", 1000)
    println("Customer")
    @time run_predictions(20, "customer.default", 1, 100, "random/raw_max_20s.csv", 1000)
    println("Flight")
    @time run_predictions(20, "flight.default", 1, 100, "random/raw_max_20s.csv", 1000)
    println("Booking")
    @time run_predictions(20, "booking.default", 1, 100, "random/raw_max_20s.csv", 1000)
end
